{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = load_model('./modeldata/pen_classification_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'BluePen', 1: 'NoPen', 2: 'TVStand', 3: 'OrangePen', 4: 'GreenPen'}\n"
     ]
    }
   ],
   "source": [
    "Object_labels = {}\n",
    "lines = []\n",
    "with open(\"./modeldata/labels.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    labels_substrings = line.split(\" \")\n",
    "    myStringLabel = \"\".join(labels_substrings[1:])\n",
    "    Object_labels[int(labels_substrings[0])] = myStringLabel\n",
    "    # print(labels_substrings, myStringLabel)\n",
    "\n",
    "print(Object_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batch 1 empty placeholder\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "greenpens_imgpaths = glob.glob(\"./input/greenpen/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total green images: 105\n",
      "\n",
      "Pred Dist: {'TVStand': 11, 'GreenPen': 78, 'BluePen': 2, 'OrangePen': 14} \n"
     ]
    }
   ],
   "source": [
    "preds_distribution = {}\n",
    "for green_img_path in greenpens_imgpaths:\n",
    "    image = Image.open(green_img_path)\n",
    "    size = (224, 224)\n",
    "    image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "    image_array = np.asarray(image)\n",
    "    # Normalize the image\n",
    "    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "    # Load the image into the array\n",
    "    data[0] = normalized_image_array\n",
    "\n",
    "    # run the inference\n",
    "    prediction = model.predict(data)\n",
    "    pred_max_index = np.argmax(prediction,axis=-1)[0]\n",
    "    Pred_label = Object_labels[pred_max_index]\n",
    "    PredConfidence = prediction[0][pred_max_index]\n",
    "\n",
    "    # print(f\"path: {green_img_path} prediction: {Pred_label} Confi: {PredConfidence}\")\n",
    "\n",
    "    if Pred_label in preds_distribution:\n",
    "        preds_distribution[Pred_label]+=1\n",
    "    else:\n",
    "        preds_distribution[Pred_label]=1\n",
    "\n",
    "\n",
    "print(f\"Total green images: {len(greenpens_imgpaths)}\\n\\nPred Dist: {preds_distribution} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('aditws')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "863280ba650ff282e4fd2b97a80aaf8b52fa93fdadab6175359562f78959ac24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
